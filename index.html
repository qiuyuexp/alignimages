<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Retinal Image Alignment (Frontend Only)</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        
        .container {
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        h1 {
            color: #333;
            text-align: center;
        }
        
        .upload-section {
            text-align: center;
            margin: 20px 0;
            padding: 20px;
            border: 2px dashed #ccc;
            border-radius: 8px;
        }
        
        .upload-section.dragover {
            background-color: #e9ecef;
            border-color: #007bff;
        }
        
        #fileInput {
            display: none;
        }
        
        .upload-btn {
            background-color: #007bff;
            color: white;
            padding: 10px 20px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
            margin: 10px;
        }
        
        .upload-btn:hover {
            background-color: #0056b3;
        }
        
        .upload-btn:disabled {
            background-color: #ccc;
            cursor: not-allowed;
        }
        
        #preview {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin: 20px 0;
            justify-content: center;
        }
        
        .preview-image {
            max-width: 200px;
            max-height: 200px;
            object-fit: contain;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        
        #result {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            margin: 20px auto;
            width: 100%;
        }
        
        canvas {
            max-width: 100%;
            max-height: 600px;
        }
        
        .loading {
            display: none;
            text-align: center;
            margin: 20px 0;
        }

        .progress-container {
            display: none;
            width: 200px;
            margin: 10px auto;
            background-color: #f0f0f0;
            border-radius: 10px;
            padding: 3px;
        }

        .progress-bar {
            width: 0%;
            height: 20px;
            background: linear-gradient(45deg, #4CAF50, #45a049);
            border-radius: 8px;
            transition: width 0.3s ease;
        }

        .progress-text {
            display: none;
            margin-top: 10px;
            font-size: 14px;
            color: #666;
        }

        @keyframes pulse {
            0% { opacity: 0.6; }
            50% { opacity: 1; }
            100% { opacity: 0.6; }
        }
        
        .error {
            color: red;
            text-align: center;
            margin: 10px 0;
            display: none;
        }

        #alignmentPoints {
            margin-top: 20px;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 4px;
        }

        .point-set {
            margin-bottom: 10px;
            padding: 5px;
            border-bottom: 1px solid #dee2e6;
        }

        #status {
            text-align: center;
            margin: 10px 0;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Retinal Image Alignment (Frontend Only)</h1>
        
        <div id="status">Loading OpenCV.js...</div>
        
        <div class="upload-section" id="dropZone">
            <input type="file" id="fileInput" multiple accept="image/*">
            <button class="upload-btn" onclick="document.getElementById('fileInput').click()" disabled>
                Select Images
            </button>
            <p>or drag and drop images here</p>
            <p>(Select 2-5 retinal images)</p>
        </div>
        
        <div id="preview"></div>
        
        <div style="text-align: center;">
            <button class="upload-btn" id="alignBtn" style="display: none;">
                Align Images
            </button>
        </div>
        
        <div class="loading" id="loading">
            Processing images... Please wait...
            <div class="progress-container">
                <div class="progress-bar" id="progressBar"></div>
            </div>
            <div class="progress-text" id="progressText">Initializing...</div>
        </div>
        
        <div class="error" id="error"></div>
        
        <div id="result">
            <canvas id="resultCanvas"></canvas>
        </div>
        <div id="alignmentPoints"></div>
    </div>

    <!-- Load OpenCV.js -->
    <script async src="https://docs.opencv.org/4.8.0/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
    <script src="https://unpkg.com/jszip@3.7.1/dist/jszip.min.js"></script>

    <script>
        let uploadedImages = [];
        let isProcessing = false;
        let homographies = [];

        function onOpenCvReady() {
            document.getElementById('status').textContent = 'OpenCV.js is ready.';
            document.querySelector('.upload-btn').disabled = false;
        }

        const dropZone = document.getElementById('dropZone');
        const fileInput = document.getElementById('fileInput');
        const preview = document.getElementById('preview');
        const alignBtn = document.getElementById('alignBtn');
        const loading = document.getElementById('loading');
        const error = document.getElementById('error');
        const resultCanvas = document.getElementById('resultCanvas');
        const alignmentPointsDiv = document.getElementById('alignmentPoints');
        
        dropZone.addEventListener('dragover', (e) => {
            e.preventDefault();
            dropZone.classList.add('dragover');
        });
        
        dropZone.addEventListener('dragleave', () => {
            dropZone.classList.remove('dragover');
        });
        
        dropZone.addEventListener('drop', (e) => {
            e.preventDefault();
            dropZone.classList.remove('dragover');
            handleFiles(e.dataTransfer.files);
        });
        
        fileInput.addEventListener('change', (e) => {
            handleFiles(e.target.files);
        });

        function handleFiles(files) {
            if (files.length < 2 || files.length > 5) {
                showError('Please select 2-5 images');
                return;
            }
            
            preview.innerHTML = '';
            uploadedImages = [];
            
            Array.from(files).forEach((file, index) => {
                if (!file.type.startsWith('image/')) {
                    showError('Please select only image files');
                    return;
                }
                
                const reader = new FileReader();
                reader.onload = (e) => {
                    const img = new Image();
                    img.onload = () => {
                        const canvas = document.createElement('canvas');
                        canvas.width = img.width;
                        canvas.height = img.height;
                        const ctx = canvas.getContext('2d');
                        ctx.drawImage(img, 0, 0);
                        
                        const previewImg = document.createElement('img');
                        previewImg.classList.add('preview-image');
                        previewImg.src = canvas.toDataURL();
                        preview.appendChild(previewImg);
                        
                        uploadedImages.push({
                            element: img,
                            file: file,
                            index: index
                        });
                        
                        if (uploadedImages.length === files.length) {
                            alignBtn.style.display = 'inline-block';
                        }
                    };
                    img.src = e.target.result;
                };
                reader.readAsDataURL(file);
            });
            
            hideError();
            resultCanvas.style.display = 'none';
            alignmentPointsDiv.innerHTML = '';
        }

        // Add configuration object for alignment parameters
        const alignmentConfig = {
            orbFeatures: 13000,        // Increased feature detection
            matchRatio: 0.65,        // More relaxed matching threshold
            ransacReprojThreshold: 0.8, // More tolerant of geometric variations
            minMatches: 18,           // Lower minimum matches requirement
            maxFeatures: 12300        // Increased upper limit
        };

        async function alignImages() {
            if (isProcessing || uploadedImages.length < 2) return;
            isProcessing = true;
            alignBtn.disabled = true;
            hideError();

            const progressContainer = document.querySelector('.progress-container');
            const progressBar = document.getElementById('progressBar');
            const progressText = document.getElementById('progressText');
            
            // Show progress elements
            loading.style.display = 'block';
            progressContainer.style.display = 'block';
            progressText.style.display = 'block';
            
            function updateProgress(percent, text) {
                progressBar.style.width = percent + '%';
                progressText.textContent = text;
            }

            // Reset progress bar
            progressBar.style.width = '0%';
            updateProgress(0, 'Starting alignment process...');

            try {
                await new Promise(resolve => setTimeout(resolve, 100)); // Small delay to show initial state
                updateProgress(10, 'Preparing reference image...');
                // Read and preprocess the reference image
                const referenceImg = cv.imread(uploadedImages[0].element);

                const alignedImages = [referenceImg]; // Keep original for output
                const alignmentPoints = [[[0, 0], 
                    [referenceImg.cols/2, referenceImg.rows/2],
                    [referenceImg.cols-1, referenceImg.rows-1]]];

                homographies = [];

                // Process each image after the reference
                for (let i = 1; i < uploadedImages.length; i++) {
                    const progress = 10 + (i / uploadedImages.length) * 70;
                    updateProgress(progress, `Processing image ${i} of ${uploadedImages.length-1}...`);

                    const currentImg = cv.imread(uploadedImages[i].element);
                    const gray1 = new cv.Mat();
                    const gray2 = new cv.Mat();
                    cv.cvtColor(currentImg, gray1, cv.COLOR_RGB2GRAY);
                    cv.cvtColor(referenceImg, gray2, cv.COLOR_RGB2GRAY);

                    // Crop out 75px from bottom only
                    const cropBottom = 75;
                    let cropped1 = gray1.roi(new cv.Rect(
                        0,  // x start from left edge
                        0,  // y start from top edge
                        gray1.cols,  // full width
                        gray1.rows - cropBottom  // height minus bottom crop
                    ));
                    let cropped2 = gray2.roi(new cv.Rect(
                        0,  // x start from left edge
                        0,  // y start from top edge
                        gray2.cols,  // full width
                        gray2.rows - cropBottom  // height minus bottom crop
                    ));

                    // Apply gamma correction to enhance contrast
                    const gamma = 3.0; // < 1 makes light areas lighter
                    const maxVal = 255;
                    const gamma1 = new cv.Mat();
                    const gamma2 = new cv.Mat();
                    
                    // Convert to float and normalize to 0-1
                    cropped1.convertTo(gamma1, cv.CV_32F, 1.0/maxVal);
                    cropped2.convertTo(gamma2, cv.CV_32F, 1.0/maxVal);
                    
                    // Apply power-law transformation
                    for(let i = 0; i < gamma1.rows; i++) {
                        for(let j = 0; j < gamma1.cols; j++) {
                            const pixel = gamma1.floatPtr(i, j);
                            pixel[0] = Math.pow(pixel[0], gamma) * maxVal;
                        }
                    }
                    for(let i = 0; i < gamma2.rows; i++) {
                        for(let j = 0; j < gamma2.cols; j++) {
                            const pixel = gamma2.floatPtr(i, j);
                            pixel[0] = Math.pow(pixel[0], gamma) * maxVal;
                        }
                    }
                    
                    // Convert back to 8-bit
                    gamma1.convertTo(gamma1, cv.CV_8U);
                    gamma2.convertTo(gamma2, cv.CV_8U);

                    // Clean up cropped mats as we'll use gamma corrected ones
                    cropped1.delete();
                    cropped2.delete();
                    cropped1 = gamma1;
                    cropped2 = gamma2;

                    // Initialize ORB detector with increased number of features
                    const orb = new cv.ORB(alignmentConfig.orbFeatures);
                    
                    const keypoints1 = new cv.KeyPointVector();
                    const keypoints2 = new cv.KeyPointVector();
                    const descriptors1 = new cv.Mat();
                    const descriptors2 = new cv.Mat();

                    // Detect keypoints and compute descriptors on cropped images
                    const mask = new cv.Mat();
                    orb.detectAndCompute(cropped1, mask, keypoints1, descriptors1);
                    orb.detectAndCompute(cropped2, mask, keypoints2, descriptors2);

                    // Adjust keypoint coordinates (no adjustment needed for x since we're not cropping sides)
                    for (let j = 0; j < keypoints1.size(); j++) {
                        const kp = keypoints1.get(j);
                        if (kp.pt.y >= gray1.rows - cropBottom) {
                            kp.pt.y = gray1.rows - cropBottom - 1;
                        }
                    }
                    for (let j = 0; j < keypoints2.size(); j++) {
                        const kp = keypoints2.get(j);
                        if (kp.pt.y >= gray2.rows - cropBottom) {
                            kp.pt.y = gray2.rows - cropBottom - 1;
                        }
                    }

                    // Sort keypoints by response strength
                    const sortedKeypoints1 = Array.from({length: keypoints1.size()}, (_, i) => ({
                        index: i,
                        response: keypoints1.get(i).response
                    })).sort((a, b) => b.response - a.response)
                      .slice(0, alignmentConfig.maxFeatures);

                    const sortedKeypoints2 = Array.from({length: keypoints2.size()}, (_, i) => ({
                        index: i,
                        response: keypoints2.get(i).response
                    })).sort((a, b) => b.response - a.response)
                      .slice(0, alignmentConfig.maxFeatures);

                    // Match descriptors using k-nearest neighbors
                    const matcher = new cv.BFMatcher(cv.NORM_HAMMING);
                    const matches = new cv.DMatchVectorVector();
                    matcher.knnMatch(descriptors1, descriptors2, matches, 2);

                    // Apply ratio test with configurable threshold
                    const good_matches = [];
                    
                    for (let j = 0; j < matches.size(); j++) {
                        const match_vec = matches.get(j);
                        if (match_vec.size() >= 2) {
                            const m = match_vec.get(0);  // Best match
                            const n = match_vec.get(1);  // Second best match
                            
                            // Check if the keypoints are in our sorted lists
                            const queryInList = sortedKeypoints1.some(k => k.index === m.queryIdx);
                            const trainInList = sortedKeypoints2.some(k => k.index === m.trainIdx);
                            
                            if (queryInList && trainInList && m.distance < alignmentConfig.matchRatio * n.distance) {
                                good_matches.push(m);
                            }
                        }
                    }

                    if (good_matches.length < alignmentConfig.minMatches) {
                        throw new Error(`Not enough good matches found between images (${good_matches.length} < ${alignmentConfig.minMatches})`);
                    }

                    // Extract location of good matches
                    const points1 = [];
                    const points2 = [];
                    for (let j = 0; j < good_matches.length; j++) {
                        const match = good_matches[j];
                        const point1 = keypoints1.get(match.queryIdx).pt;
                        const point2 = keypoints2.get(match.trainIdx).pt;
                        points1.push(point1);
                        points2.push(point2);
                    }

                    // Convert points to the format needed by findHomography
                    const srcPoints = cv.matFromArray(points1.length, 1, cv.CV_32FC2, 
                        points1.flatMap(p => [p.x, p.y]));
                    const dstPoints = cv.matFromArray(points2.length, 1, cv.CV_32FC2, 
                        points2.flatMap(p => [p.x, p.y]));

                    // Find homography with RANSAC and configurable threshold
                    const H = cv.findHomography(srcPoints, dstPoints, cv.RANSAC, alignmentConfig.ransacReprojThreshold);
                    
                    // Store homography matrix
                    const hData = new Float32Array(H.data64F);
                    homographies.push(new cv.Mat(3, 3, cv.CV_32F));
                    homographies[i-1].data32F.set(hData);

                    // Calculate transformed points for visualization
                    const points = [[0, 0], 
                        [currentImg.cols/2, currentImg.rows/2],
                        [currentImg.cols-1, currentImg.rows-1]];
                    
                    const transformedPoints = points.map(point => {
                        const x = (H.data64F[0] * point[0] + H.data64F[1] * point[1] + H.data64F[2]) /
                                (H.data64F[6] * point[0] + H.data64F[7] * point[1] + H.data64F[8]);
                        const y = (H.data64F[3] * point[0] + H.data64F[4] * point[1] + H.data64F[5]) /
                                (H.data64F[6] * point[0] + H.data64F[7] * point[1] + H.data64F[8]);
                        return [x, y];
                    });
                    alignmentPoints.push(transformedPoints);

                    // Warp image
                    const alignedImg = new cv.Mat();
                    cv.warpPerspective(currentImg, alignedImg, H, new cv.Size(referenceImg.cols, referenceImg.rows));
                    alignedImages.push(alignedImg);

                    // Clean up
                    currentImg.delete();
                    gray1.delete();
                    gray2.delete();
                    descriptors1.delete();
                    descriptors2.delete();
                    keypoints1.delete();
                    keypoints2.delete();
                    matches.delete();
                    mask.delete();
                    srcPoints.delete();
                    dstPoints.delete();
                    H.delete();
                    cropped1.delete();  // This now deletes gamma1
                    cropped2.delete();  // This now deletes gamma2
                }

                // Create result canvas
                resultCanvas.width = referenceImg.cols;
                resultCanvas.height = referenceImg.rows;
                
                // Blend images
                const result = new cv.Mat();
                cv.addWeighted(alignedImages[0], 1.0 / uploadedImages.length, alignedImages[1], 1.0 / uploadedImages.length, 0, result);
                for (let i = 2; i < alignedImages.length; i++) {
                    cv.addWeighted(result, 1.0, alignedImages[i], 1.0 / uploadedImages.length, 0, result);
                }

                // Show result
                cv.imshow(resultCanvas, result);
                resultCanvas.style.display = 'block';

                // Display alignment points
                displayAlignmentPoints(alignmentPoints);

                // Cleanup
                result.delete();
                alignedImages.forEach(img => img.delete());

            } catch (err) {
                console.error(err);
                showError('Error during alignment: ' + err.message);
                updateProgress(0, 'Error occurred');
            } finally {
                updateProgress(100, 'Complete!');
                setTimeout(() => {
                    loading.style.display = 'none';
                    progressContainer.style.display = 'none';
                    progressText.style.display = 'none';
                    progressBar.style.width = '0%';
                }, 1000);
                alignBtn.disabled = false;
                isProcessing = false;
            }
        }

        function displayAlignmentPoints(points) {
            const container = document.getElementById('alignmentPoints');
            container.innerHTML = '<h3>Alignment Points Visualization:</h3>';

            // Calculate rotation angle and center for each image based on the matched points
            uploadedImages.forEach((img, index) => {
                const imageDiv = document.createElement('div');
                imageDiv.style.marginBottom = '30px';
                imageDiv.innerHTML = `<h4>Image ${index + 1}</h4>`;

                // Create canvas for visualization
                const canvas = document.createElement('canvas');
                canvas.width = img.element.width;
                canvas.height = img.element.height;
                const ctx = canvas.getContext('2d');
                ctx.drawImage(img.element, 0, 0);

                // Calculate rotation angle from points
                let angle = 0;
                if (index > 0 && points[index].length >= 2) {
                    // Calculate angle between corresponding points in reference and current image
                    const dx1 = points[0][1][0] - points[0][0][0];
                    const dy1 = points[0][1][1] - points[0][0][1];
                    const dx2 = points[index][1][0] - points[index][0][0];
                    const dy2 = points[index][1][1] - points[index][0][1];
                    
                    angle = Math.atan2(dy2, dx2) - Math.atan2(dy1, dx1);
                }

                // Draw rotated points and their connections
                ctx.save();
                if (index > 0) {
                    // Find center point of the image
                    const centerX = img.element.width / 2;
                    const centerY = img.element.height / 2;
                    
                    // Translate to center, rotate, and translate back
                    ctx.translate(centerX, centerY);
                    ctx.rotate(angle);
                    ctx.translate(-centerX, -centerY);
                }

                // Draw points with numbers
                points[index].forEach((point, i) => {
                    // Draw point
                    ctx.beginPath();
                    ctx.arc(point[0], point[1], 3, 0, 2 * Math.PI);
                    ctx.fillStyle = '#ff0000';
                    ctx.fill();

                    // Draw point number
                    ctx.font = '12px Arial';
                    ctx.fillStyle = 'white';
                    ctx.strokeStyle = 'black';
                    ctx.lineWidth = 2;
                    ctx.strokeText(`${i + 1}`, point[0] + 5, point[1] - 5);
                    ctx.fillText(`${i + 1}`, point[0] + 5, point[1] - 5);
                });

                // Connect points with lines to show rotation
                ctx.beginPath();
                ctx.moveTo(points[index][0][0], points[index][0][1]);
                for (let i = 1; i < points[index].length; i++) {
                    ctx.lineTo(points[index][i][0], points[index][i][1]);
                }
                ctx.closePath();
                ctx.strokeStyle = '#00ff00';
                ctx.lineWidth = 2;
                ctx.stroke();

                // Add rotation angle information
                if (index > 0) {
                    const angleText = `Rotation: ${(angle * 180 / Math.PI).toFixed(2)}°`;
                    ctx.font = '14px Arial';
                    ctx.fillStyle = 'white';
                    ctx.strokeStyle = 'black';
                    ctx.lineWidth = 3;
                    ctx.strokeText(angleText, 10, 20);
                    ctx.fillText(angleText, 10, 20);
                }

                ctx.restore();

                // Add point coordinates table
                const coordTable = document.createElement('table');
                coordTable.style.border = '1px solid #ccc';
                coordTable.style.borderCollapse = 'collapse';
                coordTable.style.marginBottom = '10px';
                coordTable.innerHTML = `
                    <tr>
                        <th style="padding: 5px; border: 1px solid #ccc;">Point</th>
                        <th style="padding: 5px; border: 1px solid #ccc;">X</th>
                        <th style="padding: 5px; border: 1px solid #ccc;">Y</th>
                    </tr>
                    ${points[index].map((point, i) => `
                        <tr>
                            <td style="padding: 5px; border: 1px solid #ccc;">${i + 1}</td>
                            <td style="padding: 5px; border: 1px solid #ccc;">${point[0].toFixed(2)}</td>
                            <td style="padding: 5px; border: 1px solid #ccc;">${point[1].toFixed(2)}</td>
                        </tr>
                    `).join('')}
                `;
                imageDiv.appendChild(coordTable);
                imageDiv.appendChild(canvas);
                container.appendChild(imageDiv);
            });

            // Add download button
            const downloadAllBtn = document.createElement('button');
            downloadAllBtn.textContent = 'Download All Cropped Images';
            downloadAllBtn.style.display = 'block';
            downloadAllBtn.style.margin = '20px auto';
            downloadAllBtn.style.padding = '12px 24px';
            downloadAllBtn.style.backgroundColor = '#4CAF50';
            downloadAllBtn.style.color = 'white';
            downloadAllBtn.style.border = 'none';
            downloadAllBtn.style.borderRadius = '4px';
            downloadAllBtn.style.cursor = 'pointer';
            downloadAllBtn.style.fontSize = '16px';
            downloadAllBtn.onclick = function() {
                const zip = new JSZip();

                // First, calculate the size that will be used for all images
                let maxWidth = 0;
                let maxHeight = 0;
                uploadedImages.forEach(img => {
                    maxWidth = Math.max(maxWidth, img.element.width);
                    maxHeight = Math.max(maxHeight, img.element.height);
                });

                // Calculate the common size based on the maximum dimensions
                const commonWidth = maxWidth;
                const commonHeight = maxHeight;

                // Create OpenCV matrices for the first (reference) image
                const firstMat = cv.imread(uploadedImages[0].element);
                
                uploadedImages.forEach((img, index) => {
                    // Create a canvas for the transformed image
                    const canvas = document.createElement('canvas');
                    const ctx = canvas.getContext('2d');
                    
                    // Set canvas size to the common size
                    canvas.width = commonWidth;
                    canvas.height = commonHeight;

                    // Clear the canvas with white background
                    ctx.fillStyle = 'white';
                    ctx.fillRect(0, 0, canvas.width, canvas.height);

                    if (index === 0) {
                        // For the reference image, just draw it directly
                        ctx.drawImage(img.element, 0, 0);
                    } else {
                        // For other images, apply the same homography transformation as used in alignment
                        const currentMat = cv.imread(img.element);
                        const alignedMat = new cv.Mat();
                        
                        // Use the same homography matrix that was calculated during alignment
                        cv.warpPerspective(
                            currentMat,
                            alignedMat,
                            homographies[index-1],
                            new cv.Size(commonWidth, commonHeight)
                        );

                        // Convert the OpenCV Mat to an image that can be drawn on canvas
                        cv.imshow(canvas, alignedMat);

                        // Clean up OpenCV matrices
                        currentMat.delete();
                        alignedMat.delete();
                    }

                    // Convert canvas to blob and add to zip
                    const imageData = canvas.toDataURL('image/png').split(',')[1];
                    zip.file(`aligned_image_${index + 1}.png`, imageData, {base64: true});
                });

                // Clean up the first OpenCV matrix
                firstMat.delete();

                // Generate and download the zip file
                zip.generateAsync({type: 'blob'}).then(function(content) {
                    const link = document.createElement('a');
                    link.href = URL.createObjectURL(content);
                    link.download = 'aligned_images.zip';
                    link.click();
                });
            };
            container.appendChild(downloadAllBtn);
        }

        alignBtn.addEventListener('click', alignImages);
        
        function showError(message) {
            error.textContent = message;
            error.style.display = 'block';
        }
        
        function hideError() {
            error.style.display = 'none';
        }
    </script>
</body>
</html>
